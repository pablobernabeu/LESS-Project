#```{r setup, include=FALSE}
library(dplyr)
library(readr)
library(tidyverse)
library(janitor)
library(readxl)
# Define the path
path_to_DGS <- "Background/Gorilla/Session1"
# Read the files
DGS_1 <- read_csv(file.path(path_to_DGS, "DGS_DGS.csv"))
DGS_2 <- read_csv(file.path(path_to_DGS, "DGS_STROOP.csv"))
DGS_3 <- read_csv(file.path(path_to_DGS, "DGS_ASRT.csv"))
# Upload the additional CSV files
DGS_1_extra <- read_csv(file.path(path_to_DGS, "qdvg4_DGS_DGS.csv"))
DGS_2_extra_1 <- read_csv(file.path(path_to_DGS, "wbij5_DGS_STROOP.csv"))
DGS_2_extra_2 <- read_csv(file.path(path_to_DGS, "xqls8_DGS_STROOP.csv"))
problems(DGS_2_extra_2)
View(DGS_2_extra_2)
#```{r setup, include=FALSE}
library(dplyr)
library(readr)
library(tidyverse)
library(janitor)
library(readxl)
# Define the path
path_to_DGS <- "Background/Gorilla/Session1"
# Read the files
DGS_1 <- read_csv(file.path(path_to_DGS, "DGS_DGS.csv"))
DGS_2 <- read_csv(file.path(path_to_DGS, "DGS_STROOP.csv"))
DGS_3 <- read_csv(file.path(path_to_DGS, "DGS_ASRT.csv"))
# Clear column names
colnames(DGS_1) <- make.names(colnames(DGS_1))
colnames(DGS_2) <- make.names(colnames(DGS_2))
colnames(DGS_3) <- make.names(colnames(DGS_3))
# Select columns to combine
DGS_1 <- DGS_1 %>%
select(Attempt, Correct, display, listLength, Reaction.Time, Participant.Public.ID)
DGS_2 <- DGS_2 %>%
select(Attempt, Correct, display, listLength, Reaction.Time, Participant.Public.ID)
DGS_3 <- DGS_3 %>%
select(Attempt, Correct, display, listLength, Reaction.Time, Participant.Public.ID)
# Combine the dataframes
merged_DGS <- bind_rows(DGS_1, DGS_2, DGS_3)
# Group data by Participant.Private.ID
grouped_DGS <- merged_DGS %>%
group_by(Participant.Public.ID)
# To calculate the average Correct per participant:
avg_correct <- grouped_DGS %>%
summarize(avg_correct = mean(Correct))
print(avg_correct)
# Calculate the total number of correct digits per participant
total_correct <- merged_DGS %>%
group_by(Participant.Public.ID) %>%
summarize(total_correct = sum(Correct))
print(total_correct)
######
#####
# Calculate the number of correct digits for each list length per participant
scores_by_length <- merged_DGS %>%
group_by(Participant.Public.ID, listLength) %>%
summarize(total_correct = sum(Correct))
print(scores_by_length)
# Calculate the number of errors per type and per participant
errors <- merged_DGS %>%
group_by(Participant.Public.ID) %>%
summarize(omissions = sum(ifelse(Correct == 0 & is.na(display), 1, 0)),
intrusions = sum(ifelse(Correct == 0 & !is.na(display), 1, 0)),
repetitions = sum(ifelse(Correct == 0 & display == "Repeat", 1, 0)))
print(errors)
# Combine the results into a single table
analysis_table_DGS <- left_join(total_correct, scores_by_length, by = "Participant.Public.ID") %>%
left_join(errors, by = "Participant.Public.ID")
print(analysis_table_DGS)
write_csv(analysis_table_DGS, "testanalysis_table_DGS.csv")
#A greater number of correctly remembered digits indicates a greater
#working memory capacity.```
#total.correct.x refers to the total number of correct responses per participant
#across lists
#total.correct.y refers to the total number of correct responses per participant
#for each specific list
#```{r setup, include=FALSE}
library(dplyr)
library(readr)
library(tidyverse)
library(janitor)
library(readxl)
# Define the path
path_to_DGS <- "Background/Gorilla/Session1"
# Read the files
DGS_1 <- read_csv(file.path(path_to_DGS, "DGS_DGS.csv"))
DGS_2 <- read_csv(file.path(path_to_DGS, "DGS_STROOP.csv"))
DGS_3 <- read_csv(file.path(path_to_DGS, "DGS_ASRT.csv"))
# Upload the additional CSV files
DGS_1_extra <- read_csv(file.path(path_to_DGS, "qdvg4_DGS_DGS.csv"))
DGS_2_extra_1 <- read_csv(file.path(path_to_DGS, "wbij5_DGS_STROOP.csv"))
DGS_2_extra_2 <- read_csv(file.path(path_to_DGS, "xqls8_DGS_STROOP.csv"))
#```{r setup, include=FALSE}
library(dplyr)
library(readr)
library(tidyverse)
library(janitor)
library(readxl)
# Define the path
path_to_DGS <- "Background/Gorilla/Session1"
# Read the files
DGS_1 <- read_csv(file.path(path_to_DGS, "DGS_DGS.csv"))
DGS_2 <- read_csv(file.path(path_to_DGS, "DGS_STROOP.csv"))
DGS_3 <- read_csv(file.path(path_to_DGS, "DGS_ASRT.csv"))
# Combine the data frames
DGS_1 <- bind_rows(DGS_1, DGS_1_extra)
View(summary_statistics_by_length)
DGS <- read.csv("Background/Gorilla/analysis_table_DGS.csv")
summary_statistics_overall <- analysis_table_DGS %>%
summarize(
mean_total_correct = mean(total_correct.x, na.rm = TRUE),
median_total_correct = median(total_correct.x, na.rm = TRUE),
sd_total_correct = sd(total_correct.x, na.rm = TRUE),
min_total_correct = min(total_correct.x, na.rm = TRUE),
max_total_correct = max(total_correct.x, na.rm = TRUE)
)
print(summary_statistics_overall)
DGS <- read.csv("Background/Gorilla/analysis_table_DGS.csv")
summary_statistics_overall <- analysis_table_DGS %>%
summarize(
mean_total_correct = mean(total_correct.x, na.rm = TRUE),
median_total_correct = median(total_correct.x, na.rm = TRUE),
sd_total_correct = sd(total_correct.x, na.rm = TRUE),
min_total_correct = min(total_correct.x, na.rm = TRUE),
max_total_correct = max(total_correct.x, na.rm = TRUE)
)
summary_statistics_overall <- DGS %>%
summarize(
mean_total_correct = mean(total_correct.x, na.rm = TRUE),
median_total_correct = median(total_correct.x, na.rm = TRUE),
sd_total_correct = sd(total_correct.x, na.rm = TRUE),
min_total_correct = min(total_correct.x, na.rm = TRUE),
max_total_correct = max(total_correct.x, na.rm = TRUE)
)
print(summary_statistics_overall)
View(summary_statistics_overall)
#Examine how participants perform based on different task conditions, such as
#list length. This helps to understand if task difficulty (list length) affects
#performance.
performance_by_list_length <- DGS %>%
group_by(listLength) %>%
summarize(
mean_correct = mean(Correct, na.rm = TRUE),
median_correct = median(Correct, na.rm = TRUE),
sd_correct = sd(Correct, na.rm = TRUE),
min_correct = min(Correct, na.rm = TRUE),
max_correct = max(Correct, na.rm = TRUE)
)
View(performance_by_list_length)
#Examine how participants perform based on different task conditions, such as
#list length. This helps to understand if task difficulty (list length) affects
#performance.
performance_by_list_length <- DGS %>%
group_by(listLength) %>%
summarize(
mean_correct = mean(Correct, na.rm = TRUE),
median_correct = median(Correct, na.rm = TRUE),
sd_correct = sd(Correct, na.rm = TRUE),
min_correct = min(Correct, na.rm = TRUE),
max_correct = max(Correct, na.rm = TRUE)
)
View(performance_by_list_length)
DGS <- read.csv("Background/Gorilla/analysis_table_DGS.csv")
summary_statistics <-DGS %>%
summarize(
mean_correct = mean(Correct, na.rm = TRUE),
median_correct = median(Correct, na.rm = TRUE),
sd_correct = sd(Correct, na.rm = TRUE),
min_correct = min(Correct, na.rm = TRUE),
max_correct = max(Correct, na.rm = TRUE),
mean_reaction_time = mean(Reaction.Time, na.rm = TRUE),
sd_reaction_time = sd(Reaction.Time, na.rm = TRUE)
)
View(summary_statistics)
View(DGS)
summary_statistics <-DGS %>%
summarize(
mean_correct = mean(total_correct.x, na.rm = TRUE),
median_correct = median(total_correct.x, na.rm = TRUE),
sd_correct = sd(total_correct.x, na.rm = TRUE),
min_correct = min(total_correct.x, na.rm = TRUE),
max_correct = max(total_correct.x, na.rm = TRUE),
mean_reaction_time = mean(Reaction.Time, na.rm = TRUE),
sd_reaction_time = sd(Reaction.Time, na.rm = TRUE)
)
View(summary_statistics)
summary_statistics <-DGS %>%
summarize(
mean_correct = mean(total_correct.x, na.rm = TRUE),
median_correct = median(total_correct.x, na.rm = TRUE),
sd_correct = sd(total_correct.x, na.rm = TRUE),
min_correct = min(total_correct.x, na.rm = TRUE),
max_correct = max(total_correct.x, na.rm = TRUE),
)
View(summary_statistics)
#Examine how participants perform based on different task conditions, such as
#list length. This helps to understand if task difficulty (list length) affects
#performance.
performance_by_list_length <- DGS %>%
group_by(listLength) %>%
summarize(
mean_correct = mean(total_correct.y, na.rm = TRUE),
median_correct = median(total_correct.y, na.rm = TRUE),
sd_correct = sd(total_correct.y, na.rm = TRUE),
min_correct = min(total_correct.y, na.rm = TRUE),
max_correct = max(total_correct.y, na.rm = TRUE)
)
View(performance_by_list_length)
#```{r setup, include=FALSE}
library(dplyr)
library(readr)
library(tidyverse)
library(janitor)
library(readxl)
# Define the path
path_to_STROOP <- "Background/Gorilla/Session1"
# Read the files
STROOP_1 <- read_csv(file.path(path_to_STROOP, "STROOP_DGS.csv"))
STROOP_2 <- read_csv(file.path(path_to_STROOP, "STROOP_STROOP.csv"))
STROOP_3 <- read_csv(file.path(path_to_STROOP, "STROOP_ASRT.csv"))
# Upload the additional CSV files
STROOP_1_extra <- read_csv(file.path(path_to_STROOP, "qdvg4_STROOP_DGS.csv"))
STROOP_2_extra_1 <- read_csv(file.path(path_to_STROOP, "wbij5_STROOP_STROOP.csv"))
STROOP_2_extra_2 <- read_csv(file.path(path_to_STROOP, "xqls8_STROOP_STROOP.csv"))
# Convert the "Reaction Time" column in both data frames to numeric type (double)
STROOP_1$`Reaction Time` <- as.numeric(STROOP_1$`Reaction Time`)
#Warning message:NAs introduced by coercion
STROOP_1_extra$`Reaction Time` <- as.numeric(STROOP_1_extra$`Reaction Time`)
# Combine the data frames
STROOP_1 <- bind_rows(STROOP_1, STROOP_1_extra)
STROOP_2 <- bind_rows(STROOP_2, STROOP_2_extra_1, STROOP_2_extra_2)
#Clean column names
colnames(STROOP_1) <- make.names(colnames(STROOP_1))
colnames(STROOP_2) <- make.names(colnames(STROOP_2))
colnames(STROOP_3) <- make.names(colnames(STROOP_3))
print(colnames(STROOP_1))
# Select relevant columns
STROOP_1 <- STROOP_1 %>%
select(Reaction.Time, Participant.Public.ID, Correct, Incorrect, Congruency, Zone.Type)
STROOP_2 <- STROOP_2 %>%
select(Reaction.Time, Participant.Public.ID, Correct, Incorrect, Congruency,Zone.Type)
STROOP_3 <- STROOP_3 %>%
select(Reaction.Time, Participant.Public.ID, Correct, Incorrect, Congruency, Zone.Type)
# Combine the dataframes
merged_STROOP_2 <- bind_rows(STROOP_1, STROOP_2, STROOP_3)
# Filter to remove rows where Zone.Type is not "response"
merged_STROOP_2 <- merged_STROOP_2 %>%
filter(Zone.Type == "response_keyboard")
# Filter and clean the data by removing NA and ensuring Congruency is a factor
cleaned_data_STROOP <- merged_STROOP_2%>%
drop_na(Reaction.Time, Congruency) %>%
mutate(Congruency = factor(Congruency, levels = c(0, 1), labels = c("incongruent", "congruent")))
# Calculate the average reaction time according to congruence for each participant
mean_reaction_time_stroop <- cleaned_data_STROOP %>%
group_by(Participant.Public.ID, Congruency) %>%
summarize(mean_reaction_time_stroop = mean(Reaction.Time, na.rm = TRUE))
# See the result
View(mean_reaction_time_stroop)
# Calculate the difference between the reaction times of each congruence for
#each participant
#difference_reaction_time <- mean_reaction_time_stroop %>%
# group_by(Participant.Public.ID) %>%
#pivot_wider(names_from = Congruency, values_from = mean_reaction_time) %>%
#mutate(difference_reaction_time = congruent - incongruent)
# Step 1: Split the data by participant
split_data <- split(mean_reaction_time_stroop, mean_reaction_time_stroop$Participant.Public.ID)
# Step 2: Calculate the difference for each participant
difference_list <- lapply(split_data, function(participant_data) {
congruent_time <- participant_data$mean_reaction_time_stroop[participant_data$Congruency == "congruent"]
incongruent_time <- participant_data$mean_reaction_time_stroop[participant_data$Congruency == "incongruent"]
# Calculate the difference
difference <- congruent_time - incongruent_time
# Add a new row to the data frame with the difference
participant_data$difference_reaction_time <- ifelse(participant_data$Congruency == "congruent", difference, NA)
return(participant_data)
})
# Step 3: Recombine the list back into a single data frame
difference_reaction_time <- do.call(rbind, difference_list)
# View the result
View(difference_reaction_time)
# Save the result in a CSV file
write_csv(difference_reaction_time, "difference_reaction_time_stroop.csv")
DGS <- read.csv("Background/Gorilla/analysis_table_DGS.csv")
View(DGS)
summary_statistics <-DGS %>%
summarize(
mean_correct = mean(total_correct.x, na.rm = TRUE),
median_correct = median(total_correct.x, na.rm = TRUE),
sd_correct = sd(total_correct.x, na.rm = TRUE),
min_correct = min(total_correct.x, na.rm = TRUE),
max_correct = max(total_correct.x, na.rm = TRUE),
)
View(summary_statistics)
#Examine how participants perform based on different task conditions, such as
#list length. This helps to understand if task difficulty (list length) affects
#performance.
performance_by_list_length <- DGS %>%
group_by(listLength) %>%
summarize(
mean_correct = mean(total_correct.y, na.rm = TRUE),
median_correct = median(total_correct.y, na.rm = TRUE),
sd_correct = sd(total_correct.y, na.rm = TRUE),
min_correct = min(total_correct.y, na.rm = TRUE),
max_correct = max(total_correct.y, na.rm = TRUE)
)
View(performance_by_list_length)
View(DGS)
library(dplyr)
colnames(DGS)
summary_statistics_per_participant <- DGS %>%
group_by(Participant.Public.ID) %>%
summarize(
mean_correct = mean(total_correct.x, na.rm = TRUE),
median_correct = median(total_correct.x, na.rm = TRUE),
sd_correct = sd(total_correct.x, na.rm = TRUE),
min_correct = min(total_correct.x, na.rm = TRUE),
max_correct = max(total_correct.x, na.rm = TRUE),
omissions = sum(omissions, na.rm = TRUE),    # Replace with actual column names
intrusions = sum(intrusions, na.rm = TRUE),  # Replace with actual column names
repetitions = sum(repetitions, na.rm = TRUE) # Replace with actual column names
)
summary_statistics_per_participant <- DGS %>%
filter(!is.na(Participant_ID)) %>%
group_by(Participant.Public.ID) %>%
summarize(
mean_correct = mean(total_correct.x, na.rm = TRUE),
median_correct = median(total_correct.x, na.rm = TRUE),
sd_correct = sd(total_correct.x, na.rm = TRUE),
min_correct = min(total_correct.x, na.rm = TRUE),
max_correct = max(total_correct.x, na.rm = TRUE),
omissions = sum(omissions, na.rm = TRUE),    # Replace with actual column names
intrusions = sum(intrusions, na.rm = TRUE),  # Replace with actual column names
repetitions = sum(repetitions, na.rm = TRUE) # Replace with actual column names
)
summary_statistics_per_participant <- DGS %>%
filter(!is.na(Participant.Public.ID)) %>%
group_by(Participant.Public.ID) %>%
summarize(
mean_correct = mean(total_correct.x, na.rm = TRUE),
median_correct = median(total_correct.x, na.rm = TRUE),
sd_correct = sd(total_correct.x, na.rm = TRUE),
min_correct = min(total_correct.x, na.rm = TRUE),
max_correct = max(total_correct.x, na.rm = TRUE),
omissions = sum(omissions, na.rm = TRUE),    # Replace with actual column names
intrusions = sum(intrusions, na.rm = TRUE),  # Replace with actual column names
repetitions = sum(repetitions, na.rm = TRUE) # Replace with actual column names
)
View(summary_statistics_per_participant)
summary_statistics_per_participant <- DGS %>%
filter(!is.na(Participant.Public.ID)) %>%
group_by(Participant.Public.ID) %>%
summarize(
mean_correct = mean(total_correct.x, na.rm = TRUE),
median_correct = median(total_correct.x, na.rm = TRUE),
sd_correct_per_list = sd(total_correct.y, na.rm = TRUE),
min_correct = min(total_correct.x, na.rm = TRUE),
max_correct = max(total_correct.x, na.rm = TRUE),
omissions = sum(omissions, na.rm = TRUE),    # Replace with actual column names
intrusions = sum(intrusions, na.rm = TRUE),  # Replace with actual column names
repetitions = sum(repetitions, na.rm = TRUE) # Replace with actual column names
)
View(summary_statistics_per_participant)
DGS %>%
group_by(Participant_ID) %>%
summarize(count = n()) %>%
arrange(desc(count))
#Examine how participants perform based on different task conditions, such as
#list length. This helps to understand if task difficulty (list length) affects
#performance.
DGS_performance_by_list_length <- DGS %>%
group_by(listLength) %>%
summarize(
mean_correct = mean(total_correct.y, na.rm = TRUE),
median_correct = median(total_correct.y, na.rm = TRUE),
sd_correct = sd(total_correct.y, na.rm = TRUE),
min_correct = min(total_correct.y, na.rm = TRUE),
max_correct = max(total_correct.y, na.rm = TRUE)
)
View(DGS_performance_by_list_length)
DGS_summary_statistics_per_participant_by_list_length <- DGS %>%
filter(!is.na(Participant.Public.ID)) %>%
group_by(Participant.Public.ID) %>%
summarize(
mean_correct = mean(total_correct.x, na.rm = TRUE),
median_correct = median(total_correct.x, na.rm = TRUE),
sd_correct = sd(total_correct.x, na.rm = TRUE),
min_correct = min(total_correct.x, na.rm = TRUE),
max_correct = max(total_correct.x, na.rm = TRUE),
omissions = sum(omissions, na.rm = TRUE),
intrusions = sum(intrusions, na.rm = TRUE),
repetitions = sum(repetitions, na.rm = TRUE)
)
View(DGS_summary_statistics_per_participant_by_list_length)
Stroop <- <- read.csv("Background/Gorilla/difference_reaction_time_stroop)
Stroop <- read.csv("Background/Gorilla/difference_reaction_time_stroop)
View(Stroop)
Stroop <- read.csv("Background/Gorilla/difference_reaction_time_stroop")
Stroop <- read.csv("Background/Gorilla/difference_reaction_time_stroop")
Stroop <- read.csv("Background/Gorilla/difference_reaction_time_stroop")
getwd()
Stroop <- read.csv("Background/Gorilla/difference_reaction_time_stroop.csv")
View(Stroop)
colnames(Stroop)
#correlation with stroop, DGS, 3rd
correlation_test <- cor.test(DGS$total_correct.x, Stroop$difference_reaction_time, use = "complete.obs")
DGS <- read.csv("Background/Gorilla/analysis_table_DGS.csv")
#correlation with stroop, DGS, 3rd
correlation_test <- cor.test(DGS$total_correct.x, Stroop$difference_reaction_time, use = "complete.obs")
View(DGS)
View(Stroop)
library(dplyr)
colnames(Stroop)
# Summary statistics for congruent, incongruent, and Stroop effect
Stroop_summary_statistics <- Stroop %>%
summarize(
mean_congruent = mean(mean_reaction_time_stroop_congruent, na.rm = TRUE),
sd_congruent = sd(mean_reaction_time_stroop_congruent, na.rm = TRUE),
min_congruent = min(mean_reaction_time_stroop_congruent, na.rm = TRUE),
max_congruent = max(mean_reaction_time_stroop_congruent, na.rm = TRUE),
mean_incongruent = mean(mean_reaction_time_stroop_incongruent, na.rm = TRUE),
sd_incongruent = sd(mean_reaction_time_stroop_incongruent, na.rm = TRUE),
min_incongruent = min(mean_reaction_time_stroop_incongruent, na.rm = TRUE),
max_incongruent = max(mean_reaction_time_stroop_incongruent, na.rm = TRUE),
mean_stroop_effect = mean(difference_reaction_time, na.rm = TRUE),
sd_stroop_effect = sd(difference_reaction_time, na.rm = TRUE),
min_stroop_effect = min(difference_reaction_time, na.rm = TRUE),
max_stroop_effect = max(difference_reaction_time, na.rm = TRUE)
)
# Separate the data into congruent and incongruent conditions
congruent_data <- stroop_data %>% filter(Congruency == "congruent")
# Separate the data into congruent and incongruent conditions
congruent_data <- Stroop %>% filter(Congruency == "congruent")
incongruent_data <- Stroop %>% filter(Congruency == "incongruent")
# Merge congruent and incongruent data based on Participant ID
Stroop <- Stroop %>%
inner_join(incongruent_data, by = "Participant.Public.ID", suffix = c("_congruent", "_incongruent"))
View(Stroop)
colnames(Stroop)
View(Stroop)
View(Stroop)
# Calculate the Stroop effect (difference in reaction times)
stroop_effect_data <- stroop_effect_data %>%
mutate(stroop_effect = mean_reaction_time_stroop_incongruent - mean_reaction_time_stroop_congruent)
# Calculate the Stroop effect (difference in reaction times)
Stroop <- Stroop %>%
mutate(Stroop = mean_reaction_time_stroop_incongruent - mean_reaction_time_stroop_congruent)
View(Stroop)
# Calculate the Stroop effect (difference in reaction times)
Stroop <- Stroop %>%
mutate(stroop_effect = mean_reaction_time_stroop_incongruent - mean_reaction_time_stroop_congruent)
View(Stroop)
# Summary statistics for congruent, incongruent, and Stroop effect
summary_statistics <- Stroop %>%
summarize(
mean_congruent = mean(mean_reaction_time_stroop_congruent, na.rm = TRUE),
sd_congruent = sd(mean_reaction_time_stroop_congruent, na.rm = TRUE),
min_congruent = min(mean_reaction_time_stroop_congruent, na.rm = TRUE),
max_congruent = max(mean_reaction_time_stroop_congruent, na.rm = TRUE),
mean_incongruent = mean(mean_reaction_time_stroop_incongruent, na.rm = TRUE),
sd_incongruent = sd(mean_reaction_time_stroop_incongruent, na.rm = TRUE),
min_incongruent = min(mean_reaction_time_stroop_incongruent, na.rm = TRUE),
max_incongruent = max(mean_reaction_time_stroop_incongruent, na.rm = TRUE),
mean_stroop_effect = mean(stroop_effect, na.rm = TRUE),
sd_stroop_effect = sd(stroop_effect, na.rm = TRUE),
min_stroop_effect = min(stroop_effect, na.rm = TRUE),
max_stroop_effect = max(stroop_effect, na.rm = TRUE)
)
# Display the summary statistics
print(summary_statistics)
# Display the summary statistics
View(summary_statistics)
# Group by Participant and calculate summary statistics per participant
summary_statistics_per_participant <- Stroop %>%
group_by(Participant.Public.ID) %>%
summarize(
mean_congruent = mean(mean_reaction_time_stroop_congruent, na.rm = TRUE),
sd_congruent = sd(mean_reaction_time_stroop_congruent, na.rm = TRUE),
mean_incongruent = mean(mean_reaction_time_stroop_incongruent, na.rm = TRUE),
sd_incongruent = sd(mean_reaction_time_stroop_incongruent, na.rm = TRUE),
mean_stroop_effect = mean(stroop_effect, na.rm = TRUE),
sd_stroop_effect = sd(stroop_effect, na.rm = TRUE)
)
View(summary_statistics_per_participant)
DGS <- read.csv("Background/Gorilla/analysis_table_DGS.csv")
View(DGS)
DGS_summary_statistics <-DGS %>%
summarize(
mean_correct = mean(total_correct.x, na.rm = TRUE),
median_correct = median(total_correct.x, na.rm = TRUE),
sd_correct = sd(total_correct.x, na.rm = TRUE),
min_correct = min(total_correct.x, na.rm = TRUE),
max_correct = max(total_correct.x, na.rm = TRUE),
)
DGS_summary_statistics_per_participant <- DGS %>%
filter(!is.na(Participant.Public.ID)) %>%
group_by(Participant.Public.ID) %>%
summarize(
mean_correct = mean(total_correct.x, na.rm = TRUE),
median_correct = median(total_correct.x, na.rm = TRUE),
sd_correct = sd(total_correct.x, na.rm = TRUE),
min_correct = min(total_correct.x, na.rm = TRUE),
max_correct = max(total_correct.x, na.rm = TRUE),
omissions = sum(omissions, na.rm = TRUE),
intrusions = sum(intrusions, na.rm = TRUE),
repetitions = sum(repetitions, na.rm = TRUE)
)
View(DGS_summary_statistics_per_participant)
View(DGS_summary_statistics)
