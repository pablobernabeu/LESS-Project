LHQ3_results_raw[2, 169:175] <- lapply(LHQ3_results_raw[2, 169:175], function(x) {
x <- as.character(x)
paste(Q_daily2, x, sep = "_")
})
LHQ3_results_raw[1, 176] <- "Daily_engagement_L3"
Q_daily3 <- LHQ3_results_raw[1, 176]
Q_daily3 <- as.character(Q_daily3)
LHQ3_results_raw[2, 176:182] <- lapply(LHQ3_results_raw[2, 176:182], function(x) {
x <- as.character(x)
paste(Q_daily3, x, sep = "_")
})
LHQ3_results_raw[1, 183] <- "Daily_engagement_L4"
Q_daily4 <- LHQ3_results_raw[1, 183]
Q_daily4 <- as.character(Q_daily4)
LHQ3_results_raw[2, 183:189] <- lapply(LHQ3_results_raw[2, 183:189], function(x) {
# Convert x to character if it is not already
x <- as.character(x)
paste(Q_daily4, x, sep = "_")
})
LHQ3_results_raw[1, 190] <- "L1_h/day"
Q_dailyuse1 <- LHQ3_results_raw[1, 190]
Q_dailyuse1 <- as.character(Q_dailyuse1)
LHQ3_results_raw[2, 190:194] <- lapply(LHQ3_results_raw[2, 190:194], function(x) {
x <- as.character(x)
paste(Q_dailyuse1, x, sep = "_")
})
LHQ3_results_raw[1, 195] <- "L2_h/day"
Q_dailyuse2 <- LHQ3_results_raw[1, 195]
Q_dailyuse2 <- as.character(Q_dailyuse2)
LHQ3_results_raw[2, 195:199] <- lapply(LHQ3_results_raw[2, 195:199], function(x) {
x <- as.character(x)
paste(Q_dailyuse2, x, sep = "_")
})
LHQ3_results_raw[1, 200] <- "L3_h/day"
Q_dailyuse3 <- LHQ3_results_raw[1, 200]
Q_dailyuse3 <- as.character(Q_dailyuse3)
LHQ3_results_raw[2, 200:204] <- lapply(LHQ3_results_raw[2, 200:204], function(x) {
x <- as.character(x)
paste(Q_dailyuse3, x, sep = "_")
})
LHQ3_results_raw[1, 205] <- "L4_h/day"
Q_dailyuse4 <- LHQ3_results_raw[1, 205]
Q_dailyuse4 <- as.character(Q_dailyuse4)
LHQ3_results_raw[2, 205:209] <- lapply(LHQ3_results_raw[2, 205:209], function(x) {
x <- as.character(x)
paste(Q_dailyuse4, x, sep = "_")
})
LHQ3_results_raw[1, 210] <- "Codeswitching"
Q_Daily_codeswitching <- LHQ3_results_raw[1, 210]
Q_Daily_codeswitching <- as.character(Q_Daily_codeswitching)
LHQ3_results_raw[2, 210:221] <- lapply(LHQ3_results_raw[2, 210:221], function(x) {
x <- as.character(x)
paste(Q_Daily_codeswitching, x, sep = "_")
})
LHQ3_results_raw[1, 222] <- "Dominance/comfort"
Q_Selfrated_language_dominance <- LHQ3_results_raw[1, 222]
Q_Selfrated_language_dominance <- as.character(Q_Selfrated_language_dominance)
LHQ3_results_raw[2, 222:237] <- lapply(LHQ3_results_raw[2, 222:237], function(x) {
x <- as.character(x)
paste(Q_Selfrated_language_dominance, x, sep = "_")
})
LHQ3_results_raw[1, 238] <- "L1_internal_use_for"
Q_L1_for <- LHQ3_results_raw[1, 238]
Q_L1_for <- as.character(Q_L1_for)
LHQ3_results_raw[2, 238:245] <- lapply(LHQ3_results_raw[2, 238:245], function(x) {
x <- as.character(x)
paste(Q_L1_for, x, sep = "_")
})
LHQ3_results_raw[1, 246] <- "L2_internal_use_for"
Q_L2_for <- LHQ3_results_raw[1, 246]
Q_L2_for <- as.character(Q_L2_for)
LHQ3_results_raw[2, 246:253] <- lapply(LHQ3_results_raw[2, 246:253], function(x) {
x <- as.character(x)
paste(Q_L2_for, x, sep = "_")
})
LHQ3_results_raw[1, 254] <- "L3_internal_use_for"
Q_L3_for <- LHQ3_results_raw[1, 254]
Q_L3_for <- as.character(Q_L3_for)
LHQ3_results_raw[2, 254:261] <- lapply(LHQ3_results_raw[2, 254:261], function(x) {
x <- as.character(x)
paste(Q_L3_for, x, sep = "_")
})
LHQ3_results_raw[1, 262] <- "L4_internal_use_for"
Q_L4_for <- LHQ3_results_raw[1, 262]
Q_L4_for <- as.character(Q_L4_for)
LHQ3_results_raw[2, 262:269] <- lapply(LHQ3_results_raw[2, 262:269], function(x) {
x <- as.character(x)
paste(Q_L4_for, x, sep = "_")
})
LHQ3_results_raw[1, 270] <- "%Friends_who_speak_L1"
Q_L1_competence_friends <- LHQ3_results_raw[1, 270]
Q_L1_competence_friends <- as.character(Q_L1_competence_friends)
LHQ3_results_raw[2, 270:271] <- lapply(LHQ3_results_raw[2, 270:271], function(x) {
x <- as.character(x)
paste(Q_L1_competence_friends, x, sep = "_")
})
LHQ3_results_raw[1, 272] <- "%Friends_who_speak_L2"
Q_L2_competence_friends <- LHQ3_results_raw[1, 272]
Q_L2_competence_friends <- as.character(Q_L2_competence_friends)
LHQ3_results_raw[2, 272:273] <- lapply(LHQ3_results_raw[2, 272:273], function(x) {
x <- as.character(x)
paste(Q_L2_competence_friends, x, sep = "_")
})
LHQ3_results_raw[1, 274] <- "%Friends_who_speak_L3"
Q_L2_competence_friends <- LHQ3_results_raw[1, 274]
Q_L2_competence_friends <- as.character(Q_L2_competence_friends)
LHQ3_results_raw[2, 274:275] <- lapply(LHQ3_results_raw[2, 274:275], function(x) {
x <- as.character(x)
paste(Q_L2_competence_friends, x, sep = "_")
})
LHQ3_results_raw[1, 276] <- "%Friends_who_speak_L4%"
Q_L2_competence_friends <- LHQ3_results_raw[1, 276]
Q_L2_competence_friends <- as.character(Q_L2_competence_friends)
LHQ3_results_raw[2, 276:277] <- lapply(LHQ3_results_raw[2, 276:277], function(x) {
x <- as.character(x)
paste(Q_L2_competence_friends, x, sep = "_")
})
LHQ3_results_raw[1, 278] <- "Identification_with_L1"
Q_L1_cultural_identification <- LHQ3_results_raw[1, 278]
Q_L1_cultural_identification <- as.character(Q_L1_cultural_identification)
LHQ3_results_raw[2, 278:284] <- lapply(LHQ3_results_raw[2, 278:284], function(x) {
x <- as.character(x)
paste(Q_L1_cultural_identification, x, sep = "_")
})
LHQ3_results_raw[1, 285] <- "Identification_with_L2"
Q_L2_cultural_identification <- LHQ3_results_raw[1, 285]
Q_L2_cultural_identification <- as.character(Q_L2_cultural_identification)
LHQ3_results_raw[2, 285:291] <- lapply(LHQ3_results_raw[2, 285:291], function(x) {
x <- as.character(x)
paste(Q_L2_cultural_identification, x, sep = "_")
})
LHQ3_results_raw[1, 292] <- "Identification_with_L3"
Q_L3_cultural_identification <- LHQ3_results_raw[1, 292]
Q_L3_cultural_identification <- as.character(Q_L3_cultural_identification)
LHQ3_results_raw[2, 292:298] <- lapply(LHQ3_results_raw[2, 292:298], function(x) {
x <- as.character(x)
paste(Q_L3_cultural_identification, x, sep = "_")
})
LHQ3_results_raw[1, 299] <- "Identification_with_L4"
Q_L4_cultural_identification <- LHQ3_results_raw[1, 299]
Q_L4_cultural_identification <- as.character(Q_L4_cultural_identification)
LHQ3_results_raw[2, 299:305] <- lapply(LHQ3_results_raw[2, 299:305], function(x) {
x <- as.character(x)
paste(Q_L4_cultural_identification, x, sep = "_")
})
#Organising the data frame so it can be easily analysed, first by making the
#question/condition the header
#Removing the first row which includes the shorthanded questions and Na values
#making the more informative second row a header
LHQ3_results_raw <- LHQ3_results_raw[-1, ]
new_header <- LHQ3_results_raw[1, ]
LHQ3_results_raw <- LHQ3_results_raw[-1, ]
new_header <- as.character(new_header)
names(LHQ3_results_raw) <- new_header
logbook_path <- ("Background/LHQ3/Norway site, session_logbook.xlsx")
Norway_session_logbook <- read_excel(logbook_path, col_names = TRUE)
names(Norway_session_logbook)[names(Norway_session_logbook)
== "participant_home_ID"] <- "Participant_ID"
names(Norway_session_logbook)[names(Norway_session_logbook)
== "participant_lab_ID"] <- "Participant_number"
names(Norway_session_logbook)[names(Norway_session_logbook)
== "language"] <- "Pseudolanguage_version"
# Select only the renamed columns
Norway_session_logbook <- Norway_session_logbook[, c("Participant_ID",
"Participant_number", "Pseudolanguage_version")]
# Perform the left join using merge()
LHQ3_data_compact <- merge(LHQ3_results_raw, Norway_session_logbook, by =
"Participant_ID", all.x = TRUE)
# Rename 'Participant_number.y' to 'Participant_number'
names(LHQ3_data_compact)[names(LHQ3_data_compact) == "Participant_number.y"]  <- "Participant_number"
# Drop the 'Participant_number.x' column from the result
LHQ3_data_compact <- LHQ3_data_compact[, !names(LHQ3_data_compact) %in% "Participant_number.x"]
codeswitching_score <- c("Codeswitching_Frequency of mixing with family\nmembers",
"Codeswitching_Frequency of mixing with\nfriends",
"Codeswitching_Frequency of mixing with\nclassmates",
"Codeswitching_Frequency of mixing with\nothers")
# Step 2: Convert the specified columns to numeric
LHQ3_data_compact[, codeswitching_score] <- lapply(LHQ3_data_compact[, codeswitching_score], function(x) {
num_x <- as.numeric(as.character(x))
return(num_x)
})
# Step 3: Replace NA values with 0 in the converted columns
LHQ3_data_compact[, codeswitching_score][is.na(LHQ3_data_compact[, codeswitching_score])] <- 0
# Step 4: Calculate the row-wise average for the specified columns
LHQ3_data_compact$Codeswitching_average <- rowMeans(LHQ3_data_compact[, codeswitching_score], na.rm = TRUE)
file_path2 <- ("Background/LHQ3/LHQ3 Aggregate Scores.xlsx")
LHQ3_processed <- read_excel(file_path2, sheet = "Sheet1", col_names = FALSE)
LHQ3_processed <- LHQ3_processed [-1, ]
LHQ3_processed <- LHQ3_processed %>%
row_to_names(row_number = 1)
View(LHQ3_processed)
# Rename columns using indices
names(LHQ3_processed)[c(1, 6, 7, 14)] <- c("Participant_ID", "L1_Proficiency_Score",
"L2_Proficiency_Score", "Multilingual_Language_Diversity_Score")
# Ensure 'Participant_ID' is present in both data frames for merging
LHQ3_final <- merge(LHQ3_data_compact, LHQ3_processed, by = "Participant_ID")
# View the final data frame
View(LHQ3_final)
# Ensure 'Participant_ID' is present in both data frames for merging
LHQ3_combined <- merge(LHQ3_data_compact, LHQ3_processed, by = "Participant_ID")
View(LHQ3_combined)
# Ensure 'Participant_ID' is present in both data frames for merging
LHQ3_processed <- merge(LHQ3_data_compact, LHQ3_processed, by = "Participant_ID")
View(LHQ3_processed)
# Step 2: Select Relevant Columns
LHQ3_data_compact_selected <- LHQ3_data_compact[, c("Participant_ID", "Participant_number", "Pseudolanguage_version", "Codeswitching_average")]
LHQ3_processed_selected <- LHQ3_processed[, c("Participant_ID", "L1_Proficiency_Score", "L2_Proficiency_Score", "Multilingual_Language_Diversity_Score")]
# View the final data frame
View(LHQ3_final)
# Step 2: Select Relevant Columns
LHQ3_data_compact_selected <- LHQ3_data_compact[, c("Participant_ID", "Participant_number", "Pseudolanguage_version", "Codeswitching_average")]
LHQ3_processed_selected <- LHQ3_processed[, c("Participant_ID", "L1_Proficiency_Score", "L2_Proficiency_Score", "Multilingual_Language_Diversity_Score")]
# View the final data frame
View(LHQ3_final)
# Step 3: Perform a Left Join
LHQ3_final <- merge(LHQ3_data_compact_selected, LHQ3_processed_selected, by = "Participant_ID", all.x = TRUE)
# View the final data frame
View(LHQ3_final)
#loading the behavioural data from Session1
Stroop <- read.csv("Background/Gorilla/difference_reaction_time_stroop.csv")
TL <- read.csv("Background/Gorilla/TL_RT_wide_1.csv")
DGS <- read.csv("Background/Gorilla/analysis_table_DGS.csv")
View(DGS)
View(Stroop)
View(TL)
# Combine the data frames based on Participant Public ID using full_join
Session1_data <- DGS %>%
full_join(Stroop, by = "Participant.Public.ID", relationship = "many-to-many") %>%
full_join(TL, by = "Participant.Public.ID", relationship = "many-to-many")
# View the combined data
View(Session1_data)
# Rename the column 'Participant.Public.ID' to 'Participant_ID'
names(Session1_data)[names(Session1_data) == "Participant.Public.ID"] <- "Participant_ID"
# Merge the two data frames by 'Participant_ID'
Backgound_data <- merge(LHQ3_final, Session1_data, by = "Participant_ID")
# View the merged data
View(Backgound_data)
# Save to a specific directory
write.csv(Background_data, "/Background/Background_data.csv", row.names = FALSE)
# Merge the two data frames by 'Participant_ID'
Background_data <- merge(LHQ3_final, Session1_data, by = "Participant_ID")
# View the merged data
View(Background_data)
# Save to a specific directory
write.csv(Background_data, "/Background/Background_data.csv", row.names = FALSE)
getwd()
# Save to a specific directory
write.csv(Background_data, "/Background/Background_data.csv", row.names = FALSE)
# Save to a specific directory
write.csv(Background_data, "Background/Background_data.csv", row.names = FALSE)
# Load the CSV file into a new data frame
Background_data <- read.csv("Background/Background_data.csv", header = TRUE)
# Check the loaded data
head(Background_data)
# Check the loaded data
View(Background_data)
# Load the Background data CSV file
Background_data <- read.csv("Background/Background_data.csv", header = TRUE)
library(tidyverse)
library(reshape2)
library(janitor)
library(plyr)
#session2, remove participants 2 and 7 from anovas
Session2path <- "EEG/data/Session 2/Export/"
#creating patterns to import the files and recognise them as distinct conditions
# the final number in the file name indicates the Grammaticality of the trial
#files that end in:
# 101: the trial was grammatical
# 102: the trial presented a violation of interest
# 103: the trial presented an ancillary violation
#Session 2 investigates Gender agreement, indicated by the marker S1
Session2_gram_files <- list.files(pattern = "*S1.S101.txt",
path = Session2path, full.names = TRUE)
Session2_violation_interest <- list.files(pattern = "*S1_S102.txt",
path = Session2path, full.names = TRUE)
Session2_ancillary_violation <- list.files(pattern = "*S1_S103.txt",
path = Session2path, full.names = TRUE)
# Constructing lists of data, one for each condition
Session2_gram_list = lapply(1:length(Session2_gram_files),function(x) {
read.table(Session2_gram_files[x], header=FALSE) } )
Session2_violation_interest_list = lapply(1:length(Session2_violation_interest),
function(x) {
read.table(Session2_violation_interest[x], header=FALSE) } )
Session2_ancillary_violation_list = lapply(1:length(Session2_ancillary_violation),
function(x) {
read.table(Session2_ancillary_violation [x], header=FALSE) } )
# Convert the 'Time' column to numeric
Session2_melted_data_dirty$Time <- as.numeric (as.character
(Session2_melted_data_dirty$Time))
# Add a Session column
Session2_melted_data_dirty$Session <- 'Session 2'
# View the resulting melted data
View(Session2_melted_data_dirty)
# Load the Background data CSV file
Background_data <- read.csv("Background/Background_data.csv", header = TRUE)
library(tidyverse)
library(reshape2)
library(janitor)
library(plyr)
#session2, remove participants 2 and 7 from anovas
Session2path <- "EEG/data/Session 2/Export/"
#creating patterns to import the files and recognise them as distinct conditions
# the final number in the file name indicates the Grammaticality of the trial
#files that end in:
# 101: the trial was grammatical
# 102: the trial presented a violation of interest
# 103: the trial presented an ancillary violation
#Session 2 investigates Gender agreement, indicated by the marker S1
Session2_gram_files <- list.files(pattern = "*S1.S101.txt",
path = Session2path, full.names = TRUE)
Session2_violation_interest <- list.files(pattern = "*S1_S102.txt",
path = Session2path, full.names = TRUE)
Session2_ancillary_violation <- list.files(pattern = "*S1_S103.txt",
path = Session2path, full.names = TRUE)
# Constructing lists of data, one for each condition
Session2_gram_list = lapply(1:length(Session2_gram_files),function(x) {
read.table(Session2_gram_files[x], header=FALSE) } )
Session2_violation_interest_list = lapply(1:length(Session2_violation_interest),
function(x) {
read.table(Session2_violation_interest[x], header=FALSE) } )
# Load the Background data CSV file
Background_data <- read.csv("Background/Background_data.csv", header = TRUE)
library(tidyverse)
library(reshape2)
library(janitor)
library(plyr)
#session2, remove participants 2 and 7 from anovas
Session2path <- "EEG/data/Session 2/Export/"
#creating patterns to import the files and recognise them as distinct conditions
# the final number in the file name indicates the Grammaticality of the trial
#files that end in:
# 101: the trial was grammatical
# 102: the trial presented a violation of interest
# 103: the trial presented an ancillary violation
#Session 2 investigates Gender agreement, indicated by the marker S1
Session2_gram_files <- list.files(pattern = "*S1.S101.txt",
path = Session2path, full.names = TRUE)
Session2_violation_interest <- list.files(pattern = "*S1_S102.txt",
path = Session2path, full.names = TRUE)
Session2_ancillary_violation <- list.files(pattern = "*S1_S103.txt",
path = Session2path, full.names = TRUE)
# Constructing lists of data, one for each condition
Session2_gram_list = lapply(1:length(Session2_gram_files),function(x) {
read.table(Session2_gram_files[x], header=FALSE) } )
Session6path <- "EEG/data/Session 6/Export/"
Session6_GEN_gram_files <- list.files(pattern = "*S1_S101.txt",
path = Session4path, full.names = TRUE)
Session6_GEN_gram_files <- list.files(pattern = "*S1_S101.txt",
path = Session6path, full.names = TRUE)
Session6_GEN_violation_interest <- list.files(pattern = "*S1_S102.txt",
path = Session6path, full.names = TRUE)
Session6_GEN_ancillary_violation <- list.files(pattern = "*S1_S103.txt",
path = Session6path, full.names = TRUE)
Session6_DOM_gram_files <- list.files(pattern = "*S2_S101.txt",
path = Session6path, full.names = TRUE)
Session6_DOM_violation_interest <- list.files(pattern = "*S2_S102.txt",
path = Session6path, full.names = TRUE)
Session6_DOM_ancillary_violation <- list.files(pattern = "*S2_S103.txt",
path = Session6path, full.names = TRUE)
Session6_VOA_gram_files <- list.files(pattern = "*S3_S101.txt",
path = Session4path, full.names = TRUE)
Session6_VOA_gram_files <- list.files(pattern = "*S3_S101.txt",
path = Session6path, full.names = TRUE)
Session6_VOA_violation_interest <- list.files(pattern = "*S3_S102.txt",
path = Session6path, full.names = TRUE)
Session6_VOA_ancillary_violation <- list.files(pattern = "*S3_S103.txt",
path = Session6path, full.names = TRUE)
Session6_GEN_gram_list = lapply(1:length(Session6_GEN_gram_files),function(x) {
read.table(Session6_GEN_gram_files[x], header=FALSE) } )
Session6_GEN_violation_interest_list = lapply(1:length(Session6_GEN_violation_interest),
function(x) { read.table(Session6_GEN_violation_interest [x], header=FALSE) } )
Session6_GEN_ancillary_violation_list = lapply(1:length(Session6_GEN_ancillary_violation),
function(x) { read.table(Session6_GEN_ancillary_violation [x], header=FALSE) } )
Session6_DOM_gram_list = lapply(1:length(Session6_DOM_gram_files),function(x) {
read.table(Session6_DOM_gram_files[x], header=FALSE) } )
Session6_DOM_violation_interest_list = lapply(1:length(Session6_DOM_violation_interest),
function(x) { read.table(Session6_DOM_violation_interest[x], header=FALSE) } )
Session6_DOM_ancillary_violation_list = lapply(1:length(Session6_DOM_ancillary_violation),
function(x) { read.table(Session6_DOM_ancillary_violation [x], header=FALSE) } )
Session6_VOA_gram_list = lapply(1:length(Session6_VOA_gram_files),function(x) {
read.table(Session6_VOA_gram_files[x], header=FALSE) } )
Session6_VOA_violation_interest_list = lapply(1:length(Session6_VOA_violation_interest),
function(x) { read.table(Session6_VOA_violation_interest[x], header=FALSE) } )
Session6_VOA_ancillary_violation_list = lapply(1:length(Session6_VOA_ancillary_violation),
function(x) { read.table(Session6_VOA_ancillary_violation [x], header=FALSE) } )
#constructing data frames
Session6_GEN_gram_data = ldply(Session6_GEN_gram_list, data.frame)
library(tidyverse)
library(reshape2)
library(janitor)
library(plyr)
#constructing data frames
Session6_GEN_gram_data = ldply(Session6_GEN_gram_list, data.frame)
Session6_GEN_violation_interest_data = ldply(Session6_GEN_violation_interest_list,
data.frame)
Session6_GEN_ancillary_violation_data = ldply (Session6_GEN_ancillary_violation_list,
data.frame)
Session6_DOM_gram_data = ldply(Session6_DOM_gram_list, data.frame)
Session6_DOM_violation_interest_data = ldply(Session6_DOM_violation_interest_list,
data.frame)
Session6_DOM_ancillary_violation_data = ldply (Session6_DOM_ancillary_violation_list,
data.frame)
Session6_VOA_gram_data = ldply(Session6_VOA_gram_list, data.frame)
Session6_VOA_violation_interest_data = ldply(Session6_VOA_violation_interest_list,
data.frame)
Session6_VOA_ancillary_violation_data = ldply (Session6_VOA_ancillary_violation_list,
data.frame)
# time during the recording is organised in milliseconds, from -100 to 1098,
#and recorded with 2 ms intervals
seq = seq(-100, 1098, 2)
# the electrode column is formulated as a vector of electrode names that
#correspond to the time interval sequence
names(Session6_GEN_gram_data) = c('Electrode', seq)
names(Session6_GEN_violation_interest_data) = c('Electrode', seq)
names(Session6_GEN_ancillary_violation_data) = c ('Electrode', seq)
names(Session6_DOM_gram_data) = c('Electrode', seq)
names(Session6_DOM_violation_interest_data) = c('Electrode', seq)
names(Session6_DOM_ancillary_violation_data) = c ('Electrode', seq)
names(Session6_VOA_gram_data) = c('Electrode', seq)
names(Session6_VOA_violation_interest_data) = c('Electrode', seq)
names(Session6_VOA_ancillary_violation_data) = c ('Electrode', seq)
# working on the participants' name column
#removing the path from the participants' file names
file_names_S6_GEN_grammatical <- basename(Session6_GEN_gram_files)
files_names_S6_GEN_violation_interest <- basename(Session6_GEN_violation_interest)
files_names_S6_GEN_ancillary_violation <- basename(Session6_GEN_ancillary_violation)
file_names_S6_DOM_grammatical <- basename(Session6_DOM_gram_files)
files_names_S6_DOM_violation_interest <- basename(Session6_DOM_violation_interest)
files_names_S6_DOM_ancillary_violation <- basename(Session6_DOM_ancillary_violation)
file_names_S6_VOA_grammatical <- basename(Session6_VOA_gram_files)
files_names_S6_VOA_violation_interest <- basename(Session6_VOA_violation_interest)
files_names_S6_VOA_ancillary_violation <- basename(Session6_VOA_ancillary_violation)
#Extracting the participant numbers from the file name
participants_S6_GEN_grammatical <- sub("_.*", "", file_names_S6_GEN_grammatical)
participants_S6_GEN_violint = sub("_.*", "", files_names_S6_GEN_violation_interest)
participants_S6_GEN_ancvil = sub("_.*", "", files_names_S6_GEN_ancillary_violation)
participants_S6_DOM_grammatical <- sub("_.*", "", file_names_S6_DOM_grammatical)
participants_S6_DOM_violint = sub("_.*", "", files_names_S6_DOM_violation_interest)
participants_S6_DOM_ancvil = sub("_.*", "", files_names_S6_DOM_ancillary_violation)
participants_S6_VOA_grammatical <- sub("_.*", "", file_names_S6_VOA_grammatical)
participants_S6_VOA_violint = sub("_.*", "", files_names_S6_VOA_violation_interest)
participants_S6_VOA_ancvil = sub("_.*", "", files_names_S6_VOA_ancillary_violation)
# adding a "Participant_number" column to the data frames
Session6_GEN_gram_data$Participant_number <- rep(participants_S6_GEN_grammatical,
each = nrow(Session6_GEN_gram_data) / length(participants_S6_GEN_grammatical))
Session6_GEN_violation_interest_data$Participant_number <- rep(participants_S6_GEN_violint,
each = nrow(Session6_GEN_violation_interest_data) / length(participants_S6_GEN_violint))
Session6_GEN_ancillary_violation_data$Participant_number <- rep(participants_S6_GEN_ancvil,
each = nrow(Session6_GEN_ancillary_violation_data) / length(participants_S6_GEN_ancvil))
Session6_DOM_gram_data$Participant_number <- rep(participants_S6_DOM_grammatical,
each = nrow(Session6_DOM_gram_data) / length(participants_S6_DOM_grammatical))
Session6_DOM_violation_interest_data$Participant_number <- rep(participants_S6_DOM_violint,
each = nrow(Session6_DOM_violation_interest_data) / length(participants_S6_DOM_violint))
Session6_DOM_ancillary_violation_data$Participant_number <- rep(participants_S6_DOM_ancvil,
each = nrow(Session6_DOM_ancillary_violation_data) / length(participants_S6_DOM_ancvil))
Session6_VOA_gram_data$Participant_number <- rep(participants_S6_VOA_grammatical,
each = nrow(Session6_VOA_gram_data) / length(participants_S6_VOA_grammatical))
Session6_VOA_violation_interest_data$Participant_number <- rep(participants_S6_VOA_violint,
each = nrow(Session6_VOA_violation_interest_data) / length(participants_S6_VOA_violint))
Session6_VOA_ancillary_violation_data$Participant_number <- rep(participants_S6_VOA_ancvil,
each = nrow(Session6_VOA_ancillary_violation_data) / length(participants_S6_VOA_ancvil))
#Adding a Property column to the data frames
Session6_GEN_gram_data$Property <- 'Gender_Agreement'
Session6_GEN_violation_interest_data$Property <- 'Gender_Agreement'
Session6_GEN_ancillary_violation_data$Property <- 'Gender_Agreement'
Session6_DOM_gram_data$Property <- 'Differential_Object_Marking'
Session6_DOM_violation_interest_data$Property <- 'Differential_Object_Marking'
Session6_DOM_ancillary_violation_data$Property <- 'Differential_Object_Marking'
Session6_VOA_gram_data$Property <- 'Verb_Object_Number_Agreement'
Session6_VOA_violation_interest_data$Property <- 'Verb_Object_Number_Agreement'
Session6_VOA_ancillary_violation_data$Property <- 'Verb_Object_Number_Agreement'
Session6_GEN_gram_data$Grammaticality <- 'Grammatical'
Session6_GEN_violation_interest_data$Grammaticality <- 'Violation_of_Interest'
Session6_GEN_ancillary_violation_data$Grammaticality <- 'Ancillary_Violation'
Session6_DOM_gram_data$Grammaticality <- 'Grammatical'
Session6_DOM_violation_interest_data$Grammaticality <- 'Violation_of_Interest'
Session6_DOM_ancillary_violation_data$Grammaticality <- 'Ancillary_Violation'
Session6_VOA_gram_data$Grammaticality <- 'Grammatical'
Session6_VOA_violation_interest_data$Grammaticality <- 'Violation_of_Interest'
Session6_VOA_ancillary_violation_data$Grammaticality <- 'Ancillary_Violation'
Session6_combined_data <- rbind(Session6_GEN_gram_data,
Session6_GEN_violation_interest_data,
Session6_GEN_ancillary_violation_data,
Session6_DOM_gram_data,
Session6_DOM_violation_interest_data,
Session6_DOM_ancillary_violation_data,
Session6_VOA_gram_data,
Session6_VOA_violation_interest_data,
Session6_VOA_ancillary_violation_data)
View(Session6_combined_data)
Session6_VOA_gram_data$Grammaticality <- 'Grammatical'
Session6_VOA_violation_interest_data$Grammaticality <- 'Violation_of_Interest'
Session6_VOA_ancillary_violation_data$Grammaticality <- 'Ancillary_Violation'
Session6_combined_data <- rbind(Session6_GEN_gram_data,
Session6_GEN_violation_interest_data,
Session6_GEN_ancillary_violation_data,
Session6_DOM_gram_data,
Session6_DOM_violation_interest_data,
Session6_DOM_ancillary_violation_data,
Session6_VOA_gram_data,
Session6_VOA_violation_interest_data,
Session6_VOA_ancillary_violation_data)
ncol(Session6_GEN_gram_data)
ncol(Session6_GEN_violation_interest_data)
# Repeat for the other data frames
ncol(Sesssion6_GEN_ancillary_violation_data)
ncol(Session6_GEN_ancillary_violation_data)
ncol(Session6_DOM_gram_data)
ncol(Session6_DOM_violation_interest_data)
ncol(Session6_DOM_ancillary_violation_data)
ncol(Session6_VOA_gram_data)
ncol(Session6_VOA_violation_interest_data)
