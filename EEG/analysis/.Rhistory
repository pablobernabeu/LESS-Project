print("Some data frames in data_listS101 have no rows.")
}
if (all(sapply(data_listS102_S2_N300, nrow) > 0)) {
S2_S102_N300 <- Reduce(function(...) merge(..., all = TRUE),data_listS102_S2_N300)
View(S2_S102_N300)
} else {
print("Some data frames in data_list2 have no rows.")
}
Grammatical_S2_N300 <- do.call(rbind, data_listS101_S2_N300)
str(Grammatical_S2_N300)
head(Grammatical_S2_N300)
Ungrammatical_S2_N300 <- do.call(rbind, data_listS102_S2_N300)
head(Ungrammatical_S2_N300)
#converting the data lists into data frames
S2_Grammatical_N300 <- as.data.frame(Grammatical_S2_N300)
S2_Ungrammatical_N300 <- as.data.frame(Ungrammatical_S2_N300)
#converting comas to periods in the dataframe because the decimal point is a comma in BrainVision analyzer export files
S2_Grammatical_N300 <- S2_Grammatical_N300 %>%
mutate(across(everything(), ~ gsub(",",".",., fixed = TRUE)))
S2_Ungrammatical_N300 <- S2_Ungrammatical_N300 %>%
mutate(across(everything(), ~ gsub(",",".",., fixed = TRUE)))
#Converting columns to numeric if necessary
S2_Grammatical_N300 <- S2_Grammatical_N300 %>% mutate(across(everything(), as.numeric))
S2_Ungrammatical_N300 <- S2_Ungrammatical_N300 %>% mutate(across(everything(), as.numeric))
#left_medial_Grammatical
left_medial_Grammatical_row_means_S2_N300 <- rowMeans(S2_Grammatical_N300[, c("T7.Average", "C3.Average", "CP5.Average")], na.rm = TRUE)
left_medial_Grammatical_S2_N300 <- mean(left_medial_Grammatical_row_means_S2_N300, na.rm = TRUE)
right_medial_Grammatical_row_means_S2_N300 <- rowMeans(S2_Grammatical_N300 [, c("C4.Average", "T8.Average", "CP6.Average")], na.rm = TRUE)
right_medial_Grammatical_S2_N300 <- mean(right_medial_Grammatical_row_means_S2_N300, na.rm = TRUE)
left_anterior_Grammatical_row_means_S2_N300 <- rowMeans(S2_Grammatical_N300[, c("Fp1.Average", "F3.Average", "F7.Average", "FT9.Average", "FC5.Average")], na.rm = TRUE)
left_anterior_Grammatical_S2_N300 <- mean(left_anterior_Grammatical_row_means_S2_N300, na.rm = TRUE)
right_anterior_Grammatical_row_means_S2_N300 <- rowMeans(S2_Grammatical_N300[, c("Fp2.Average", "F4.Average", "F8.Average", "FC6.Average", "FT10.Average")], na.rm = TRUE)
right_anterior_Grammatical_S2_N300 <- mean(right_anterior_Grammatical_row_means_S2_N300, na.rm = TRUE)
left_posterior_Grammatical_row_means_S2_N300 <- rowMeans(S2_Grammatical_N300 [, c("TP9.Average", "P7.Average", "P3.Average", "O1.Average")], na.rm = TRUE)
left_posterior_Grammatical_S2_N300 <- mean(left_posterior_Grammatical_row_means_S2_N300, na.rm = TRUE)
right_posterior_Grammatical_row_means_S2_N300 <- rowMeans(S2_Grammatical_N300 [,c ("TP10.Average", "P4.Average", "P8.Average", "O2.Average")], na.rm = TRUE)
right_posterior_Grammatical_S2_N300 <- mean(right_posterior_Grammatical_row_means_S2_N300, na.rm = TRUE)
midline_anterior_Grammatical_row_means_S2_N300 <- rowMeans(S2_Grammatical_N300 [, c ("Fz.Average", "FC1.Average", "FC2.Average")], na.rm = TRUE)
midline_anterior_Grammatical_S2_N300 <- mean(midline_anterior_Grammatical_row_means_S2_N300, na.rm = TRUE)
midline_medial_Grammatical_row_means_S2_N300 <- rowMeans(S2_Grammatical_N300 [,c ("Cz.Average", "CP1.Average", "CP2.Average")], na.rm = TRUE)
midline_medial_Grammatical_S2_N300 <- mean(midline_medial_Grammatical_row_means_S2_N300, na.rm = TRUE)
midline_posterior_Grammatical_row_means_S2_N300 <- rowMeans(S2_Grammatical_N300[,c ("Pz.Average", "Oz.Average")], na.rm = TRUE)
midline_posterior_Grammatical_S2_N300 <- mean(midline_posterior_Grammatical_row_means_S2_N300, na.rm = TRUE)
left_medial_Ungrammatical_row_means_S2_N300 <- rowMeans(S2_Ungrammatical_N300[, c("T7.Average", "C3.Average", "CP5.Average")], na.rm = TRUE)
left_medial_Ungrammatical_S2_N300 <- mean(left_medial_Ungrammatical_row_means_S2_N300, na.rm = TRUE)
right_medial_Ungrammatical_row_means_S2_N300 <- rowMeans(S2_Ungrammatical_N300 [, c("C4.Average", "T8.Average", "CP6.Average")], na.rm = TRUE)
right_medial_Ungrammatical_S2_N300 <- mean(right_medial_Ungrammatical_row_means_S2_N300, na.rm = TRUE)
left_anterior_Ungrammatical_row_means_S2_N300 <- rowMeans(S2_Ungrammatical_N300[, c("Fp1.Average", "F3.Average", "F7.Average", "FT9.Average", "FC5.Average")], na.rm = TRUE)
left_anterior_Ungrammatical_S2_N300 <- mean(left_anterior_Ungrammatical_row_means_S2_N300, na.rm = TRUE)
right_anterior_Ungrammatical_row_means_S2_N300 <- rowMeans(S2_Ungrammatical_N300[, c("Fp2.Average", "F4.Average", "F8.Average", "FC6.Average", "FT10.Average")], na.rm = TRUE)
right_anterior_Ungrammatical_S2_N300 <- mean(right_anterior_Ungrammatical_row_means_S2_N300, na.rm = TRUE)
left_posterior_Ungrammatical_row_means_S2_N200 <- rowMeans(S2_Ungrammatical_N300 [, c("TP9.Average", "P7.Average", "P3.Average", "O1.Average")], na.rm = TRUE)
left_posterior_Ungrammatical_S2_N300 <- mean(left_posterior_Ungrammatical_row_means_S2_N200, na.rm = TRUE)
right_posterior_Ungrammatical_row_means_S2_N300 <- rowMeans(S2_Ungrammatical_N300 [,c ("TP10.Average", "P4.Average", "P8.Average", "O2.Average")], na.rm = TRUE)
right_posterior_Ungrammatical_S2_N300 <- mean(right_posterior_Ungrammatical_row_means_S2_N300, na.rm = TRUE)
midline_anterior_Ungrammatical_row_means_S2_N300 <- rowMeans(S2_Ungrammatical_N300 [, c ("Fz.Average", "FC1.Average", "FC2.Average")], na.rm = TRUE)
midline_anterior_Ungrammatical_S2_N300 <- mean(midline_anterior_Ungrammatical_row_means_S2_N300, na.rm = TRUE)
midline_medial_Ungrammatical_row_means_S2_N300 <- rowMeans(S2_Ungrammatical_N300 [,c ("Cz.Average", "CP1.Average", "CP2.Average")], na.rm = TRUE)
midline_medial_Ungrammatical_S2_N300 <- mean(midline_medial_Ungrammatical_row_means_S2_N300, na.rm = TRUE)
midline_posterior_Ungrammatical_row_means_S2_N300 <- rowMeans(S2_Ungrammatical_N300[,c ("Pz.Average", "Oz.Average")], na.rm = TRUE)
midline_posterior_Ungrammatical_S2_N300 <- mean(midline_posterior_Ungrammatical_row_means_S2_N300, na.rm = TRUE)
# Print results
print(left_medial_Ungrammatical_S2_N300)
print(left_medial_Grammatical_S2_N300)
print(right_medial_Ungrammatical_S2_N300)
print(right_medial_Grammatical_S2_N300)
print(left_anterior_Ungrammatical_S2_N300)
print(left_anterior_Grammatical_S2_N300)
print(right_anterior_Ungrammatical_S2_N300)
print(right_anterior_Grammatical_S2_N300)
print(left_posterior_Ungrammatical_S2_N300)
print(left_posterior_Grammatical_S2_N300)
print(right_posterior_Ungrammatical_S2_N300)
print(right_posterior_Grammatical_S2_N300)
print(midline_anterior_Ungrammatical_S2_N300)
print(midline_anterior_Grammatical_S2_N300)
print(midline_medial_Ungrammatical_S2_N300)
print(midline_medial_Grammatical_S2_N300)
print(midline_posterior_Ungrammatical_S2_N300)
print(midline_posterior_Grammatical_S2_N300)
pattern1_S2_N200 = "^[0-9].*N200_S101.txt"
print(pattern1_S2_N200)
pattern2_S2_N200 = "^[0-9].*N200_S102.txt"
file_listS101_S2_N200 <- list.files(pattern = pattern1_S2_N200)
print(file_listS101_S2_N200)
file_listS102_S2_N200 <- list.files(pattern = pattern2_S2_N200)
print(file_listS102_S2_N200)
pattern1_S2_N600 = "^[0-9].*N600_S101.txt"
print(pattern1_S2_N600)
pattern2_S2_N600 = "^[0-9].*N600_S102.txt"
file_listS101_S2_N600 <- list.files(pattern = pattern1_S2_N600)
print(file_listS101_S2_N600)
file_listS102_S2_N600 <- list.files(pattern = pattern2_S2_N600)
print(file_listS102_S2_N600)
data_listS101_S2_N600 <- lapply(file_listS101_S2_N600, function(file) {
read.table(file, header = TRUE, sep = "")
})
#reading table
data_listS101_S2_N600 <- lapply(file_listS101_S2_N600, function(file) {
read.table(file, header = TRUE, sep = "")
})
# Check dimensions of the first data frame
str(data_listS101_S2_N600[[1]])
head(data_listS101_S2_N600[[1]])
#ensure variables are consistent S101_N200 should have s2
#checking if rows are missing and removing them
if (all(sapply(data_listS101_S2_N600, nrow) > 0)) {
S101_N200 <- Reduce(function(...) merge(..., all = TRUE), data_listS101_S2_N600)
View(S101_N200)
} else {
print("Some data frames in data_listS101 have no rows.")
}
data_listS102_S2_N600 <- lapply(file_listS102_S2_N600, function(file) {
read.table(file, header = TRUE, sep = "")
})
lapply(data_listS102_S2_N600, head)
if (all(sapply(data_listS102_S2_N600, nrow) > 0)) {
S102_N600 <- Reduce(function(...) merge(..., all = TRUE), data_listS102_S2_N600)
View(S102_N600)
} else {
print("Some data frames in data_list2 have no rows.")
}
S2_Grammatical_N600 <- do.call(rbind, data_listS101_S2_N600)
head(S2_Grammatical_N600)
S2_Ungrammatical_N600 <- do.call(rbind, data_listS102_S2_N600)
head(S2_Ungrammatical_N600)
#converting comas to periods in the dataframe because the decimal point is a comma in BrainVision analyzer export files
S2_Grammatical_N600 <- S2_Grammatical_N600 %>%
mutate(across(everything(), ~ gsub(",",".",., fixed = TRUE)))
S2_Ungrammatical_N600 <- S2_Ungrammatical_N600 %>%
mutate(across(everything(), ~ gsub(",",".",., fixed = TRUE)))
#Converting columns to numeric if necessary
S2_Grammatical_N600 <- S2_Grammatical_N600 %>% mutate(across(everything(), as.numeric))
S2_Ungrammatical_N600 <- S2_Ungrammatical_N600 %>% mutate(across(everything(), as.numeric))
left_medial_Grammatical_row_means_S2_N600 <- rowMeans(S2_Grammatical_N600[, c("T7.Average", "C3.Average", "CP5.Average")], na.rm = TRUE)
left_medial_Grammatical_S2_N600 <- mean(left_medial_Grammatical_row_means_S2_N600, na.rm = TRUE)
right_medial_Grammatical_row_means_S2_N600 <- rowMeans(S2_Grammatical_N600 [, c("C4.Average", "T8.Average", "CP6.Average")], na.rm = TRUE)
right_medial_Grammatical_S2_N600 <- mean(right_medial_Grammatical_row_means_S2_N600, na.rm = TRUE)
left_anterior_Grammatical_row_means_S2_N600 <- rowMeans(S2_Grammatical_N600[, c("Fp1.Average", "F3.Average", "F7.Average", "FT9.Average", "FC5.Average")], na.rm = TRUE)
left_anterior_Grammatical_S2_N600 <- mean(left_anterior_Grammatical_row_means_S2_N600, na.rm = TRUE)
right_anterior_Grammatical_row_means_S2_N600 <- rowMeans(S2_Grammatical_N600[, c("Fp2.Average", "F4.Average", "F8.Average", "FC6.Average", "FT10.Average")], na.rm = TRUE)
right_anterior_Grammatical_S2_N600 <- mean(right_anterior_Grammatical_row_means_S2_N600, na.rm = TRUE)
left_posterior_Grammatical_row_means_S2_N600 <- rowMeans(S2_Grammatical_N600 [, c("TP9.Average", "P7.Average", "P3.Average", "O1.Average")], na.rm = TRUE)
left_posterior_Grammatical_S2_N600 <- mean(left_posterior_Grammatical_row_means_S2_N600, na.rm = TRUE)
right_posterior_Grammatical_row_means_S2_N600 <- rowMeans(S2_Grammatical_N600 [,c ("TP10.Average", "P4.Average", "P8.Average", "O2.Average")], na.rm = TRUE)
right_posterior_Grammatical_S2_N600 <- mean(right_posterior_Grammatical_row_means_S2_N600, na.rm = TRUE)
midline_anterior_Grammatical_row_means_S2_N600 <- rowMeans(S2_Grammatical_N600 [, c ("Fz.Average", "FC1.Average", "FC2.Average")], na.rm = TRUE)
midline_anterior_Grammatical_S2_N600 <- mean(midline_anterior_Grammatical_row_means_S2_N600, na.rm = TRUE)
midline_medial_Grammatical_row_means_S2_N600 <- rowMeans(S2_Grammatical_N600 [,c ("Cz.Average", "CP1.Average", "CP2.Average")], na.rm = TRUE)
midline_medial_Grammatical_S2_N600 <- mean(midline_medial_Grammatical_row_means_S2_N600, na.rm = TRUE)
midline_posterior_Grammatical_row_means_S2_N600 <- rowMeans(S2_Grammatical_N600[,c ("Pz.Average", "Oz.Average")], na.rm = TRUE)
midline_posterior_Grammatical_S2_N600 <- mean(midline_posterior_Grammatical_row_means_S2_N600, na.rm = TRUE)
left_medial_Ungrammatical_row_means_S2_N600 <- rowMeans(S2_Ungrammatical_N600[, c("T7.Average", "C3.Average", "CP5.Average")], na.rm = TRUE)
left_medial_Ungrammatical_S2_N600 <- mean(left_medial_Ungrammatical_row_means_S2_N600, na.rm = TRUE)
right_medial_Ungrammatical_row_means_S2_N600 <- rowMeans(S2_Ungrammatical_N600 [, c("C4.Average", "T8.Average", "CP6.Average")], na.rm = TRUE)
right_medial_Ungrammatical_S2_N600 <- mean(right_medial_Ungrammatical_row_means_S2_N600, na.rm = TRUE)
left_anterior_Ungrammatical_row_means_S2_N600 <- rowMeans(S2_Ungrammatical_N600[, c("Fp1.Average", "F3.Average", "F7.Average", "FT9.Average", "FC5.Average")], na.rm = TRUE)
left_anterior_Ungrammatical_S2_N600 <- mean(left_anterior_Ungrammatical_row_means_S2_N600, na.rm = TRUE)
right_anterior_Ungrammatical_row_means_S2_N600 <- rowMeans(S2_Ungrammatical_N600[, c("Fp2.Average", "F4.Average", "F8.Average", "FC6.Average", "FT10.Average")], na.rm = TRUE)
right_anterior_Ungrammatical_S2_N600 <- mean(right_anterior_Ungrammatical_row_means_S2_N600, na.rm = TRUE)
left_posterior_Ungrammatical_row_means_S2_N600 <- rowMeans(S2_Ungrammatical_N600 [, c("TP9.Average", "P7.Average", "P3.Average", "O1.Average")], na.rm = TRUE)
left_posterior_Ungrammatical_S2_N600 <- mean(left_posterior_Ungrammatical_row_means_S2_N600, na.rm = TRUE)
right_posterior_Ungrammatical_row_means_S2_N600 <- rowMeans(S2_Ungrammatical_N600 [,c ("TP10.Average", "P4.Average", "P8.Average", "O2.Average")], na.rm = TRUE)
right_posterior_Ungrammatical_S2_N600 <- mean(right_posterior_Ungrammatical_row_means_S2_N600, na.rm = TRUE)
midline_anterior_Ungrammatical_row_means_S2_N600 <- rowMeans(S2_Ungrammatical_N600 [, c ("Fz.Average", "FC1.Average", "FC2.Average")], na.rm = TRUE)
midline_anterior_Ungrammatical_S2_N600 <- mean(midline_anterior_Ungrammatical_row_means_S2_N600, na.rm = TRUE)
midline_medial_Ungrammatical_row_means_S2_N600 <- rowMeans(S2_Ungrammatical_N600 [,c ("Cz.Average", "CP1.Average", "CP2.Average")], na.rm = TRUE)
midline_medial_Ungrammatical_S2_N600 <- mean(midline_medial_Ungrammatical_row_means_S2_N600, na.rm = TRUE)
midline_posterior_Ungrammatical_row_means_S2_N600 <- rowMeans(S2_Ungrammatical_N600[,c ("Pz.Average", "Oz.Average")], na.rm = TRUE)
midline_posterior_Ungrammatical_S2_N600 <- mean(midline_posterior_Ungrammatical_row_means_S2_N600, na.rm = TRUE)
# Print results
print(left_medial_Ungrammatical_S2_N600)
print(left_medial_Grammatical_S2_N600)
print(right_medial_Ungrammatical_S2_N600)
print(right_medial_Grammatical_S2_N600)
print(left_anterior_Ungrammatical_S2_N600)
print(left_anterior_Grammatical_S2_N600)
print(right_anterior_Ungrammatical_S2_N600)
print(right_anterior_Grammatical_S2_N600)
print(left_posterior_Ungrammatical_S2_N600)
print(left_posterior_Grammatical_S2_N600)
print(right_posterior_Ungrammatical_S2_N600)
print(right_posterior_Grammatical_S2_N600)
print(midline_anterior_Ungrammatical_S2_N600)
print(midline_anterior_Grammatical_S2_N600)
print(midline_medial_Ungrammatical_S2_N600)
print(midline_medial_Grammatical_S2_N600)
print(midline_posterior_Ungrammatical_S2_N600)
print(midline_posterior_Grammatical_S2_N600)
#produces a board to directly compare with no statistical analysis
Regions_N600 <- c('left_medial', 'right_medial', 'left_anterior', 'right_anterior', 'left_posterior', 'right_posterior', 'midline_anterior', 'midline_medial', 'midline_posterior')
Ungrammatical_condition <- c(left_medial_Ungrammatical_S2_N600, right_medial_Ungrammatical_S2_N600, left_anterior_Ungrammatical_S2_N600, right_anterior_Ungrammatical_S2_N600, left_posterior_Ungrammatical_S2_N600, right_posterior_Ungrammatical_S2_N600, midline_anterior_Ungrammatical_S2_N600, midline_medial_Ungrammatical_S2_N600, midline_posterior_Ungrammatical_S2_N600)
Grammatical_condition <- c(left_medial_Grammatical_S2_N600, right_medial_Grammatical_S2_N600, left_anterior_Grammatical_S2_N600, right_anterior_Grammatical_S2_N600, left_posterior_Grammatical_S2_N600, right_posterior_Grammatical_S2_N600, midline_anterior_Grammatical_S2_N600, midline_medial_Grammatical_S2_N600, midline_posterior_Grammatical_S2_N600)
df <- data.frame(Regions_N600, Ungrammatical_condition, Grammatical_condition)
View(df)
print(Regions_N600)
# same as above
#Creating a table with the average values of each region per grammatical condition
Regions <- c('left_medial', 'right_medial', 'left_anterior', 'right_anterior', 'left_posterior', 'right_posterior', 'midline_anterior', 'midline_medial', 'midline_posterior')
Grammatical <- c(left_medial_Grammatical_S2_N600, right_medial_Grammatical_S2_N600, left_anterior_Grammatical_S2_N600, right_anterior_Grammatical_S2_N600, left_posterior_Grammatical_S2_N600, right_posterior_Grammatical_S2_N600, midline_anterior_Grammatical_S2_N600, midline_medial_Grammatical_S2_N600, midline_posterior_Grammatical_S2_N600)
Ungrammatical <- c(left_medial_Ungrammatical_S2_N600, right_medial_Ungrammatical_S2_N600, left_anterior_Ungrammatical_S2_N600, right_anterior_Ungrammatical_S2_N600, left_posterior_Ungrammatical_S2_N600, right_posterior_Ungrammatical_S2_N600, midline_anterior_Ungrammatical_S2_N600, midline_medial_Ungrammatical_S2_N600, midline_posterior_Ungrammatical_S2_N600)
N600_regions_per_condition <- data.frame(
Regions = Regions,
Grammatical = Grammatical,
Ungrammatical = Ungrammatical
)
View(N600_regions_per_condition)
#ANOVAs for Session2 N600
# Sample data
AnovaforN600 <- data.frame(
ROIs = rep(c("A", "B", "C"), each = 10),
Grammaticality = c(rnorm(10, mean=5), rnorm(10, mean=6), rnorm(10, mean=7))
)
# Display the first few rows of the data
head(df)
# Direct ANOVA using wide format data
# Combine all data into one dataframe for simplicity
Grammatical <- c(left_medial_Grammatical_S2_N600, right_medial_Grammatical_S2_N600, left_anterior_Grammatical_S2_N600, right_anterior_Grammatical_S2_N600, left_posterior_Grammatical_S2_N600, right_posterior_Grammatical_S2_N600, midline_anterior_Grammatical_S2_N600, midline_medial_Grammatical_S2_N600, midline_posterior_Grammatical_S2_N600)
Ungrammatical <- c(left_medial_Ungrammatical_S2_N600, right_medial_Ungrammatical_S2_N600, left_anterior_Ungrammatical_S2_N600, right_anterior_Ungrammatical_S2_N600, left_posterior_Ungrammatical_S2_N600, right_posterior_Ungrammatical_S2_N600, midline_anterior_Ungrammatical_S2_N600, midline_medial_Ungrammatical_S2_N600, midline_posterior_Ungrammatical_S2_N600)
# Define the vectors
ROI <- rep(c("left_medial", "right_medial", "left_anterior", "right_anterior", "left_posterior", "right_posterior", "midline_anterior", "midline_medial", "midline_posterior"), 2)
Condition <- rep(c("Grammatical", "Ungrammatical"), each = 9)
Level_of_Activation <- c(left_medial_Grammatical_vector_S2_N600, right_medial_Grammatical_vector_S2_N600, left_anterior_Grammatical_vector_S2_N600, right_anterior_Grammatical_vector_S2_N600, left_posterior_Grammatical_vector_S2_N600, right_posterior_Grammatical_vector_S2_N600, midline_anterior_Grammatical_vector_S2_N600, midline_medial_Grammatical_vector_S2_N600, midline_posterior_Grammatical_vector_S2_N600,
left_medial_Ungrammatical_vector_S2_N600, right_medial_Ungrammatical_vector_S2_N600, left_anterior_Ungrammatical_vector_S2_N600, right_anterior_Ungrammatical_vector_S2_N600, left_posterior_Ungrammatical_vector_S2_N600, right_posterior_Ungrammatical_vector_S2_N600, midline_anterior_Ungrammatical_vector_S2_N600, midline_medial_Ungrammatical_vector_S2_N600, midline_posterior_Ungrammatical_vector_S2_N600)
# Combine them into a data frame
df_wide <- data.frame(ROI, Condition, Level_of_Activation)
# Perform a two-way ANOVA
anova_result_wide <- aov(Level_of_Activation ~ Condition + ROI + Condition:ROI, data = df_wide)
# Display the results
summary(anova_result_wide)
print(left_medial_Grammatical_S2_N600)
library(read)
library(readr)
install.packages(readr)
"readr"
install.packages("readr")
# participants need to be separated by language and by grammaticality
library(lme4)
library(stringr)
library(ggplot2)
library(dplyr)
library(readr)
setwd("C:/Users/chath1626/OneDrive - UiT Office 365/Desktop/LESS-Project-with-RAs-2/R analysis")
# Load necessary libraries
library(dplyr)
library(readr)
# Function to read and merge data files based on a pattern
read_and_merge_data <- function(directory, pattern) {
# Create the full path for the directory
file_paths <- list.files(path = directory, pattern = pattern, full.names = TRUE)
# Read the files into a list of data frames
data_list <- lapply(file_paths, function(file) {
read.table(file, header = TRUE, sep = "")
})
# Check if all data frames have rows
if (all(sapply(data_list, nrow) > 0)) {
merged_data <- Reduce(function(...) merge(..., all = TRUE), data_list)
return(merged_data)
} else {
print(paste("Some data frames in", directory, "have no rows."))
return(NULL)
}
}
View(read_and_merge_data)
# Check if all data frames have rows
if (all(sapply(data_list, nrow) > 0)) {
merged_data <- Reduce(function(...) merge(..., all = TRUE), data_list)
return(merged_data)
} else {
print(paste("Some data frames in", directory, "have no rows."))
return(NULL)
}
# Function to read and merge data files based on a pattern
read_and_merge_data <- function(directory, pattern) {
# Create the full path for the directory
file_paths <- list.files(path = directory, pattern = pattern, full.names = TRUE)
# Read the files into a list of data frames
data_list <- lapply(file_paths, function(file) {
read.table(file, header = TRUE, sep = "")
})
# Check if all data frames have rows
if (all(sapply(data_list, nrow) > 0)) {
merged_data <- Reduce(function(...) merge(..., all = TRUE), data_list)
return(merged_data)
} else {
print(paste("Some data frames in", directory, "have no rows."))
return(NULL)
}
}
# Define your directories
directory1 <- "C:/Users/chath1626/OneDrive - UiT Office 365/LESS-Project-with-RAs-2/Session 2/Export"
# Define your patterns
pattern1_S2_N200 <- "^[0-9].*N200_S101.txt"
pattern2_S2_N200 <- "^[0-9].*N200_S102.txt"
# Read and merge data for S101
S101_N200 <- read_and_merge_data(directory1, pattern1_S2_N200)
if (!is.null(S101_N200)) {
print("S101_N200 Data:")
print(head(S101_N200))
}
# Read and merge data for S102
S102_N200 <- read_and_merge_data(directory1, pattern2_S2_N200)
if (!is.null(S102_N200)) {
print("S102_N200 Data:")
print(head(S102_N200))
}
# Combine all data if needed
if (!is.null(S101_N200) & !is.null(S102_N200)) {
S2_Grammatical_N200 <- do.call(rbind, S101_N200)
S2_Ungrammatical_N200 <- do.call(rbind, S102_N200)
print("S2_Grammatical_N200:")
print(head(S2_Grammatical_N200))
print("S2_Ungrammatical_N200:")
print(head(S2_Ungrammatical_N200))
}
# Create the full path for the directory
file_paths <- list.files(path = "C:/Users/chath1626/OneDrive - UiT Office 365/LESS-Project-with-RAs-2", pattern = pattern, full.names = TRUE)
# Create the full path for the directory
file_paths <- list.files(path = "C:/Users/chath1626/OneDrive - UiT Office 365/LESS-Project-with-RAs-2", pattern = .txt, full.names = TRUE)
# Create the full path for the directory
file_paths <- list.files(path = "C:/Users/chath1626/OneDrive - UiT Office 365/LESS-Project-with-RAs-2", pattern = '.txt', full.names = TRUE)
# Read the files into a list of data frames
data_list <- lapply(file_paths, function(file) {
read.table(file, header = TRUE, sep = "")
})
# Check if all data frames have rows
if (all(sapply(data_list, nrow) > 0)) {
merged_data <- Reduce(function(...) merge(..., all = TRUE), data_list)
return(merged_data)
} else {
print(paste("Some data frames in", directory, "have no rows."))
return(NULL)
}
# Function to read and merge data files based on a pattern
read_and_merge_data <- function(directory, pattern) {
# Create the full path for the directory
file_paths <- list.files(path = "C:/Users/chath1626/OneDrive - UiT Office 365/LESS-Project-with-RAs-2", pattern = '.txt', full.names = TRUE)
# Read the files into a list of data frames
data_list <- lapply(file_paths, function(file) {
read.table(file, header = TRUE, sep = "")
})
# Check if all data frames have rows
if (all(sapply(data_list, nrow) > 0)) {
merged_data <- Reduce(function(...) merge(..., all = TRUE), data_list)
return(merged_data)
} else {
print(paste("Some data frames in", directory, "have no rows."))
return(NULL)
}
}
# Define your directories
directory1 <- "C:/Users/chath1626/OneDrive - UiT Office 365/LESS-Project-with-RAs-2/Session 2/Export"
# Define your patterns
pattern1_S2_N200 <- "^[0-9].*N200_S101.txt"
pattern2_S2_N200 <- "^[0-9].*N200_S102.txt"
# Read and merge data for S101
S101_N200 <- read_and_merge_data(directory1, pattern1_S2_N200)
if (!is.null(S101_N200)) {
print("S101_N200 Data:")
print(head(S101_N200))
}
# Read and merge data for S102
S102_N200 <- read_and_merge_data(directory1, pattern2_S2_N200)
if (!is.null(S102_N200)) {
print("S102_N200 Data:")
print(head(S102_N200))
}
# Combine all data if needed
if (!is.null(S101_N200) & !is.null(S102_N200)) {
S2_Grammatical_N200 <- do.call(rbind, S101_N200)
S2_Ungrammatical_N200 <- do.call(rbind, S102_N200)
print("S2_Grammatical_N200:")
print(head(S2_Grammatical_N200))
print("S2_Ungrammatical_N200:")
print(head(S2_Ungrammatical_N200))
}
N200 <- "C:/Users/chath1626/OneDrive - UiT Office 365/Desktop/LESS-Project-with-RAs-2/R analysis"
N200 = ("C:/Users/chath1626/OneDrive - UiT Office 365/Desktop/LESS-Project-with-RAs-2/R analysis")
print(N200)
class(N200)
read_data <- function("C:/Users/chath1626/OneDrive - UiT Office 365/Desktop/LESS-Project-with-RAs-2/R analysis"), pattern) {
setwd("C:/Users/chath1626/OneDrive - UiT Office 365/Desktop/LESS-Project-with-RAs-2/")
read_data <- function("C:/Users/chath1626/OneDrive - UiT Office 365/Desktop/LESS-Project-with-RAs-2/R analysis"), pattern) {
# Directory 1
directory1 <- "C:/Users/chath1626/OneDrive - UiT Office 365/Desktop/LESS-Project-with-RAs-2/Session2/Session2_Export"
# Directory 2
directory2 <- "C:/path/to/directory2"
setwd("C:/Users/chath1626/OneDrive - UiT Office 365/Desktop/LESS-Project-with-RAs-2/")
# Directory 1
directory1 <- "C:/Users/chath1626/OneDrive - UiT Office 365/Desktop/LESS-Project-with-RAs-2/Session2/Session2_Export"
# Directory 2
directory2 <- "C:/path/to/directory2"
#analysing per Session, for N200, per condition of grammaticality (Segmentation S101 = grammatical, Segmentation S102 = violation of grammaticality) while maintaining the ERP
#Session 2, N200
#creation of regex pattern in order for the programme to look for the pattern of participantNumber_ERP in two different conditions
#creation of regex pattern to create two sets of data
pattern1_S2_N200 = "^[0-9].*N200_S101.txt"
print(pattern1_S2_N200)
pattern2_S2_N200 = "^[0-9].*N200_S102.txt"
file_listS101_S2_N200 <- list.files(pattern = pattern1_S2_N200)
print(file_listS101_S2_N200)
file_listS102_S2_N200 <- list.files(pattern = pattern2_S2_N200)
print(file_listS102_S2_N200)
#Session 2, N300
pattern1_S2_N300 = "^[0-9].*N300_S101.txt"
print(pattern1_S2_N300)
pattern2_S2_N300 = "^[0-9].*N300_S102.txt"
file_listS101_S2_N300 <- list.files(pattern = pattern1_S2_N300)
print(file_listS101_S2_N300)
file_listS102_S2_N300 <- list.files(pattern = pattern2_S2_N300)
print(file_listS102_S2_N300)
#reading table
data_listS101_S2_N300 <- lapply(file_listS101_S2_N300, function(file) {
read.table(file, header = TRUE, sep = "")
})
data_listS102_S2_N300 <- lapply(file_listS102_S2_N300, function(file) {
read.table(file, header = TRUE, sep = "")
})
lapply(data_listS102_S2_N300, head)
# Check dimensions of the first data frame
str(data_listS101_S2_N300[[1]])
head(data_listS101_S2_N300[[1]])
setwd("C:/Users/chath1626/OneDrive - UiT Office 365/Desktop/LESS-Project-with-RAs-2/R analysis")
#analysing per Session, for N200, per condition of grammaticality (Segmentation S101 = grammatical, Segmentation S102 = violation of grammaticality) while maintaining the ERP
#Session 2, N200
#creation of regex pattern in order for the programme to look for the pattern of participantNumber_ERP in two different conditions
#creation of regex pattern to create two sets of data
pattern1_S2_N200 = "^[0-9].*N200_S101.txt"
library(stringr)
library(ggplot2)
library(dplyr)
library(readr)
setwd("C:/Users/chath1626/OneDrive - UiT Office 365/Desktop/LESS-Project-with-RAs-2/R analysis")
list.files()
##Give full path
list.files(full.names=TRUE)
##list files in the species1 directory
list.files("species1/", full.names=TRUE)
library(plyr)
path <- "EEG/data/Session 2/Export/"
#getting the list of files
Session2_gram_files <- list.files(pattern = "*S1.S101.txt",
path = path, full.names = TRUE)
Session2_violation_interest <- list.files(pattern = "*S1_S102.txt",
path = path, full.names = TRUE)
Session2_ancillary_violation <- list.files(pattern = "*S1_S103.txt",
path = path, full.names = TRUE)
#Checking the file paths
print(Session2_gram_files)
print(Session2_violation_interest)
print(Session2_ancillary_violation)
# Constructing lists of data
Session2_gram_list = lapply(1:length(Session2_gram_files),function(x) {
read.table(Session2_gram_files[x], header=FALSE) } )
Session2_violation_interest_list = lapply(1:length(Session2_violation_interest),function(x) {
read.table(Session2_violation_interest[x], header=FALSE) } )
Session2_ancillary_violation_list = lapply(1:length(Session2_ancillary_violation),function(x) {
read.table(Session2_ancillary_violation [x], header=FALSE) } )
View(Session2_ancillary_violation_list)
# converting the lists into data frames
Session2_gram_data = ldply(Session2_gram_list, data.frame)
Session2_violation_interest_data = ldply(Session2_violation_interest_list, data.frame)
path <- "EEG/data/Session 2/Export/"
#getting the list of files
Session2_gram_files <- list.files(pattern = "*S1.S101.txt",
path = path, full.names = TRUE)
Session2_violation_interest <- list.files(pattern = "*S1_S102.txt",
path = path, full.names = TRUE)
Session2_ancillary_violation <- list.files(pattern = "*S1_S103.txt",
path = path, full.names = TRUE)
#Checking the file paths
print(Session2_gram_files)
library(plyr)
library(reshape2)
library(magrittr)
library(dplyr)
path <- "EEG/data/Session 2/Export/"
path <- "EEG/data/Session 2/Export/"
path <- "EEG/data/Session 2/Export/"
#getting the list of files
Session2_gram_files <- list.files(pattern = "*S1.S101.txt",
path = path, full.names = TRUE)
Session2_violation_interest <- list.files(pattern = "*S1_S102.txt",
path = path, full.names = TRUE)
Session2_ancillary_violation <- list.files(pattern = "*S1_S103.txt",
path = path, full.names = TRUE)
#Checking the file paths
print(Session2_gram_files)
print(Session2_violation_interest)
print(Session2_ancillary_violation)
# Constructing lists of data
Session2_gram_list = lapply(1:length(Session2_gram_files),function(x) {
read.table(Session2_gram_files[x], header=FALSE) } )
Session2_violation_interest_list = lapply(1:length(Session2_violation_interest),function(x) {
read.table(Session2_violation_interest[x], header=FALSE) } )
Session2_ancillary_violation_list = lapply(1:length(Session2_ancillary_violation),function(x) {
read.table(Session2_ancillary_violation [x], header=FALSE) } )
View(Session2_ancillary_violation_list)
# converting the lists into data frames
Session2_gram_data = ldply(Session2_gram_list, data.frame)
Session2_violation_interest_data = ldply(Session2_violation_interest_list, data.frame)
source("EEG/analysis/1. LHQ3 Importation script.R")
source("EEG/analysis/3. Session Data importation.R")
source("EEG/analysis/LHQ3 Importation script.R")
source("EEG/analysis/Session Data importation.R")
source("EEG\analysis\1. LHQ3 importation script.R")
source("EEG\analysis\1. LHQ3 importation script.R")
source("EEG/analysis/Session Data importation.R")
"C:\Users\chath1626\OneDrive - UiT Office 365\LESS-Project-with-RAs-2\EEG\analysis\1. LHQ3 importation script.R"
setwd("C:/Users/chath1626/OneDrive - UiT Office 365/LESS-Project-with-RAs-2/EEG/analysis")
source("EEG\analysis\1. LHQ3 importation script.R")
source("EEG/analysis/Session Data importation.R")
